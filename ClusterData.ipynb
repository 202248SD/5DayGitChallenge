{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCI+j7cEw0eRYDou3To8wz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/202248SD/5DayGitChallenge/blob/main/ClusterData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/犬１-20240617T025624Z-001.zip\n",
        "!unzip /content/犬２-20240617T025639Z-001.zip"
      ],
      "metadata": {
        "id": "HCH74wSIP6nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/犬１-20240617T025624Z-001.zip\n",
        "!rm /content/犬２-20240617T025639Z-001.zip"
      ],
      "metadata": {
        "id": "tM6vR5OYQAJr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from glob import glob\n",
        "import cv2 as cv\n",
        "import shutil"
      ],
      "metadata": {
        "id": "agDPbN-4OTxG"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vkfv9pSsZGVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "DogDetector = YOLO(\"yolov8l.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5uH4h67XyYa",
        "outputId": "39525d73-4245-4236-c3e2-662fa7cfd965"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.7M/83.7M [00:00<00:00, 171MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DogTypeNet = models.resnet50(pretrained=True)\n",
        "num_ftrs = DogTypeNet.fc.in_features\n",
        "DogTypeNet.fc = torch.nn.Linear(num_ftrs, 120)\n",
        "DogTypeNet.load_state_dict(torch.load('/content/model (2).pth', map_location=torch.device('cpu')))\n",
        "idx_to_class = {0: 'Chihuahua', 1: 'Japanese_spaniel', 2: 'Maltese_dog', 3: 'Pekinese', 4: 'Shih-Tzu', 5: 'Blenheim_spaniel', 6: 'papillon', 7: 'toy_terrier', 8: 'Rhodesian_ridgeback', 9: 'Afghan_hound', 10: 'basset', 11: 'beagle', 12: 'bloodhound', 13: 'bluetick', 14: 'black-and-tan_coonhound', 15: 'Walker_hound', 16: 'English_foxhound', 17: 'redbone', 18: 'borzoi', 19: 'Irish_wolfhound', 20: 'Italian_greyhound', 21: 'whippet', 22: 'Ibizan_hound', 23: 'Norwegian_elkhound', 24: 'otterhound', 25: 'Saluki', 26: 'Scottish_deerhound', 27: 'Weimaraner', 28: 'Staffordshire_bullterrier', 29: 'American_Staffordshire_terrier', 30: 'Bedlington_terrier', 31: 'Border_terrier', 32: 'Kerry_blue_terrier', 33: 'Irish_terrier', 34: 'Norfolk_terrier', 35: 'Norwich_terrier', 36: 'Yorkshire_terrier', 37: 'wire-haired_fox_terrier', 38: 'Lakeland_terrier', 39: 'Sealyham_terrier', 40: 'Airedale', 41: 'cairn', 42: 'Australian_terrier', 43: 'Dandie_Dinmont', 44: 'Boston_bull', 45: 'miniature_schnauzer', 46: 'giant_schnauzer', 47: 'standard_schnauzer', 48: 'Scotch_terrier', 49: 'Tibetan_terrier', 50: 'silky_terrier', 51: 'soft-coated_wheaten_terrier', 52: 'West_Highland_white_terrier', 53: 'Lhasa', 54: 'flat-coated_retriever', 55: 'curly-coated_retriever', 56: 'golden_retriever', 57: 'Labrador_retriever', 58: 'Chesapeake_Bay_retriever', 59: 'German_short-haired_pointer', 60: 'vizsla', 61: 'English_setter', 62: 'Irish_setter', 63: 'Gordon_setter', 64: 'Brittany_spaniel', 65: 'clumber', 66: 'English_springer', 67: 'Welsh_springer_spaniel', 68: 'cocker_spaniel', 69: 'Sussex_spaniel', 70: 'Irish_water_spaniel', 71: 'kuvasz', 72: 'schipperke', 73: 'groenendael', 74: 'malinois', 75: 'briard', 76: 'kelpie', 77: 'komondor', 78: 'Old_English_sheepdog', 79: 'Shetland_sheepdog', 80: 'collie', 81: 'Border_collie', 82: 'Bouvier_des_Flandres', 83: 'Rottweiler', 84: 'German_shepherd', 85: 'Doberman', 86: 'miniature_pinscher', 87: 'Greater_Swiss_Mountain_dog', 88: 'Bernese_mountain_dog', 89: 'Appenzeller', 90: 'EntleBucher', 91: 'boxer', 92: 'bull_mastiff', 93: 'Tibetan_mastiff', 94: 'French_bulldog', 95: 'Great_Dane', 96: 'Saint_Bernard', 97: 'Eskimo_dog', 98: 'malamute', 99: 'Siberian_husky', 100: 'affenpinscher', 101: 'basenji', 102: 'pug', 103: 'Leonberg', 104: 'Newfoundland', 105: 'Great_Pyrenees', 106: 'Samoyed', 107: 'Pomeranian', 108: 'chow', 109: 'keeshond', 110: 'Brabancon_griffon', 111: 'Pembroke', 112: 'Cardigan', 113: 'toy_poodle', 114: 'miniature_poodle', 115: 'standard_poodle', 116: 'Mexican_hairless', 117: 'dingo', 118: 'dhole', 119: 'African_hunting_dog'}"
      ],
      "metadata": {
        "id": "cLN-E6a6nnL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5439b6a7-5709-4d4b-c283-bba2a712681d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 125MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DogTypeNet\n",
        "\n",
        "model.eval()\n",
        "\n",
        "modules = list(model.children())[:-1]\n",
        "feature_extractor = nn.Sequential(*modules)"
      ],
      "metadata": {
        "id": "ndUR0BCqQkO5"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "inu_1 = np.array(glob(\"犬１/*\"))\n",
        "inu_2 = np.array(glob(\"犬２/*\"))"
      ],
      "metadata": {
        "id": "gGdBi3qsOcno"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inu_1, inu_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEKpBoPoaJ4a",
        "outputId": "cdd05a04-d8d5-49de-ad15-7f4a01f96500"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['犬１/IMG_2392.JPG' '犬１/IMG_7842.JPG' '犬１/IMG_9769.JPG' '犬１/IMG_2516.JPG' '犬１/IMG_8840.JPG' '犬１/IMG_0606.JPG' '犬１/IMG_7258.JPG' '犬１/IMG_2387.JPG' '犬１/IMG_6122.JPG' '犬１/IMG_1796.JPG' '犬１/IMG_8698.JPG' '犬１/IMG_0614.JPG' '犬１/IMG_5230.JPG' '犬１/IMG_5789.JPG' '犬１/IMG_2519.JPG' '犬１/IMG_3488.JPG' '犬１/IMG_8699.JPG'\n",
            " '犬１/IMG_5792.JPG' '犬１/IMG_2724.JPG' '犬１/IMG_8217.JPG'] ['犬２/IMG_6879.JPG' '犬２/IMG_6910.JPG' '犬２/IMG_6912.JPG' '犬２/IMG_6864.JPG' '犬２/IMG_6899.JPG' '犬２/IMG_6903.JPG' '犬２/IMG_6870.JPG' '犬２/IMG_6897.JPG' '犬２/IMG_6882.JPG' '犬２/IMG_6869.JPG' '犬２/IMG_6891.JPG' '犬２/IMG_6884.JPG' '犬２/IMG_6868.JPG' '犬２/IMG_6909.JPG' '犬２/IMG_6867.JPG' '犬２/IMG_6860.JPG' '犬２/IMG_6876.JPG'\n",
            " '犬２/IMG_6859.JPG' '犬２/IMG_6878.JPG' '犬２/IMG_6871.JPG' '犬２/IMG_6895.JPG' '犬２/IMG_6888.JPG' '犬２/IMG_6875.JPG' '犬２/IMG_6873.JPG' '犬２/IMG_6902.JPG' '犬２/IMG_6893.JPG' '犬２/IMG_6898.JPG' '犬２/IMG_6907.JPG' '犬２/IMG_6862.JPG' '犬２/IMG_6877.JPG' '犬２/IMG_6896.JPG' '犬２/IMG_6901.JPG' '犬２/IMG_6911.JPG' '犬２/IMG_6874.JPG'\n",
            " '犬２/IMG_6880.JPG' '犬２/IMG_6881.JPG' '犬２/IMG_6913.JPG' '犬２/IMG_6892.JPG' '犬２/IMG_6906.JPG' '犬２/IMG_6885.JPG' '犬２/IMG_6883.JPG' '犬２/IMG_6889.JPG' '犬２/IMG_6865.JPG' '犬２/IMG_6887.JPG' '犬２/IMG_6890.JPG' '犬２/IMG_6908.JPG' '犬２/IMG_6866.JPG' '犬２/IMG_6886.JPG' '犬２/IMG_6905.JPG' '犬２/IMG_6861.JPG' '犬２/IMG_6872.JPG'\n",
            " '犬２/IMG_6863.JPG' '犬２/IMG_6904.JPG' '犬２/IMG_6894.JPG' '犬２/IMG_6900.JPG']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(img_path, box_coords=[]):\n",
        "  preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "  image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "  if len(box_coords) != 0:\n",
        "    image = image.crop(box_coords)\n",
        "\n",
        "  image = preprocess(image)\n",
        "\n",
        "  image = image.unsqueeze(0)\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "RFDkM7BvfE1N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, image, idx_to_label):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        output = model(image)\n",
        "\n",
        "        _, predicted_idx = torch.max(output, 1)\n",
        "\n",
        "        predicted_label = idx_to_label[predicted_idx.item()]\n",
        "\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "AKhHGhIxc1Wt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_label(label):\n",
        "  if 'poodle' in label:\n",
        "    label = 'Poodle'\n",
        "  elif 'terrier' in label:\n",
        "    label = 'Terrier'\n",
        "  else:\n",
        "    label = label[0].upper()+label[1:]\n",
        "  return label"
      ],
      "metadata": {
        "id": "nxKWplkqU5Vj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(image):\n",
        "  with torch.no_grad():\n",
        "      features = feature_extractor(image)\n",
        "  return features.squeeze()"
      ],
      "metadata": {
        "id": "KSTCckCLbyxt"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_save(input_path, crop_coords, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "        cropped_img = img.crop(crop_coords)\n",
        "        cropped_img.save(output_path)"
      ],
      "metadata": {
        "id": "gFcnjAg2eGFV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dogs(img_paths):\n",
        "  dataset_data = []\n",
        "  print(len(img_paths))\n",
        "  for img_path in img_paths:\n",
        "    results = DogDetector(img_path, conf=0.3, iou=0.3)\n",
        "\n",
        "    boxes = results[0].boxes.xyxy.tolist()\n",
        "    classes = results[0].boxes.cls.tolist()\n",
        "\n",
        "    img = cv.imread(img_path)\n",
        "    image_data = [] # [dog_img_path, label, ftrs]\n",
        "    dog_idx = 1\n",
        "\n",
        "    dir_path = 'Dogs/' + img_path[:len(img_path)-4]\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    for box, cls in zip(boxes, classes):\n",
        "      if cls != 16:\n",
        "        continue\n",
        "      else:\n",
        "        path = dir_path + f'/Dog{dog_idx}.JPG'\n",
        "\n",
        "        box_coords = [int(i) for i in box]\n",
        "\n",
        "        crop_save(img_path, box_coords, path)\n",
        "\n",
        "        box_img = process_image(img_path, box_coords)\n",
        "\n",
        "        features = extract_features(box_img).numpy()\n",
        "\n",
        "        label = predict(DogTypeNet, box_img, idx_to_class)\n",
        "        label = format_label(label)\n",
        "\n",
        "        dog_data = [path, label, features]\n",
        "        image_data.append(dog_data)\n",
        "        dog_idx += 1\n",
        "\n",
        "    dataset_data.append(image_data)\n",
        "  return dataset_data"
      ],
      "metadata": {
        "id": "5pjiw_tcW4Ow"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1_data = get_dogs(inu_1)\n",
        "dataset2_data = get_dogs(inu_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svKdP0r5a8uw",
        "outputId": "c3331eb6-42b7-4f63-a39e-076323158dd9"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "\n",
            "image 1/1 /content/犬１/IMG_2392.JPG: 640x640 1 dog, 3063.6ms\n",
            "Speed: 4.6ms preprocess, 3063.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_7842.JPG: 480x640 1 person, 1 dog, 2 suitcases, 2 chairs, 1 dining table, 2262.9ms\n",
            "Speed: 3.8ms preprocess, 2262.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_9769.JPG: 640x480 1 dog, 1 couch, 3333.3ms\n",
            "Speed: 3.8ms preprocess, 3333.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_2516.JPG: 640x480 1 person, 1 dog, 1 laptop, 1 microwave, 1 refrigerator, 2224.1ms\n",
            "Speed: 3.6ms preprocess, 2224.1ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_8840.JPG: 640x480 1 dog, 2244.9ms\n",
            "Speed: 3.6ms preprocess, 2244.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_0606.JPG: 480x640 1 person, 2 dogs, 1 tie, 2196.8ms\n",
            "Speed: 3.6ms preprocess, 2196.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_7258.JPG: 640x448 1 dog, 3271.3ms\n",
            "Speed: 3.7ms preprocess, 3271.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_2387.JPG: 480x640 1 person, 1 dog, 1 handbag, 2 chairs, 2224.9ms\n",
            "Speed: 3.6ms preprocess, 2224.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_6122.JPG: 640x480 1 bench, 1 dog, 2264.3ms\n",
            "Speed: 3.7ms preprocess, 2264.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_1796.JPG: 480x640 1 person, 1 dog, 1 bed, 1 clock, 2208.6ms\n",
            "Speed: 3.6ms preprocess, 2208.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_8698.JPG: 512x640 3 persons, 1 dog, 1 tie, 3314.9ms\n",
            "Speed: 3.7ms preprocess, 3314.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_0614.JPG: 480x640 1 person, 2 dogs, 1 tie, 2463.0ms\n",
            "Speed: 4.9ms preprocess, 2463.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_5230.JPG: 640x480 1 dog, 1 backpack, 1 suitcase, 2232.0ms\n",
            "Speed: 3.8ms preprocess, 2232.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_5789.JPG: 640x640 1 dog, 2959.0ms\n",
            "Speed: 4.7ms preprocess, 2959.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_2519.JPG: 640x480 1 person, 1 dog, 1 bottle, 1 oven, 3720.3ms\n",
            "Speed: 4.7ms preprocess, 3720.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_3488.JPG: 640x480 1 dog, 1 couch, 2223.9ms\n",
            "Speed: 3.8ms preprocess, 2223.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_8699.JPG: 640x480 1 dog, 1 couch, 2260.8ms\n",
            "Speed: 3.9ms preprocess, 2260.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_5792.JPG: 640x640 2 persons, 1 dog, 4 cups, 1 dining table, 1 microwave, 1 refrigerator, 2947.1ms\n",
            "Speed: 5.2ms preprocess, 2947.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_2724.JPG: 480x640 2 dogs, 1 couch, 3447.9ms\n",
            "Speed: 12.1ms preprocess, 3447.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬１/IMG_8217.JPG: 640x480 1 dog, 1 couch, 2236.3ms\n",
            "Speed: 3.9ms preprocess, 2236.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "55\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6879.JPG: 640x480 1 person, 1 bed, 1 teddy bear, 2237.3ms\n",
            "Speed: 4.0ms preprocess, 2237.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6910.JPG: 640x480 1 dog, 2230.6ms\n",
            "Speed: 4.0ms preprocess, 2230.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6912.JPG: 480x640 2 persons, 3 cups, 1 chair, 1 dining table, 1 laptop, 1 remote, 3463.4ms\n",
            "Speed: 7.9ms preprocess, 3463.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6864.JPG: 352x640 1 bear, 1675.6ms\n",
            "Speed: 2.7ms preprocess, 1675.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6899.JPG: 640x480 1 dog, 1 bottle, 2272.4ms\n",
            "Speed: 5.8ms preprocess, 2272.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6903.JPG: 640x480 1 dog, 2289.4ms\n",
            "Speed: 4.4ms preprocess, 2289.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6870.JPG: 480x640 3 dogs, 2961.6ms\n",
            "Speed: 3.3ms preprocess, 2961.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6897.JPG: 640x480 1 dog, 2283.9ms\n",
            "Speed: 4.3ms preprocess, 2283.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6882.JPG: 640x480 1 kite, 2241.4ms\n",
            "Speed: 4.4ms preprocess, 2241.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6869.JPG: 480x640 3 dogs, 1 potted plant, 2211.8ms\n",
            "Speed: 3.3ms preprocess, 2211.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6891.JPG: 640x480 1 dog, 3468.6ms\n",
            "Speed: 5.3ms preprocess, 3468.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6884.JPG: 640x480 1 couch, 1 teddy bear, 2264.3ms\n",
            "Speed: 4.3ms preprocess, 2264.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6868.JPG: 480x640 1 dog, 2185.6ms\n",
            "Speed: 3.1ms preprocess, 2185.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6909.JPG: 640x480 1 person, 1 dog, 2278.5ms\n",
            "Speed: 4.4ms preprocess, 2278.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6867.JPG: 480x640 2 dogs, 4021.7ms\n",
            "Speed: 10.7ms preprocess, 4021.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6860.JPG: 384x640 1 person, 2 dogs, 1864.5ms\n",
            "Speed: 3.1ms preprocess, 1864.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6876.JPG: 640x480 1 dog, 2250.8ms\n",
            "Speed: 4.0ms preprocess, 2250.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6859.JPG: 480x640 1 person, 2219.6ms\n",
            "Speed: 4.1ms preprocess, 2219.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6878.JPG: 640x480 1 dog, 3204.6ms\n",
            "Speed: 4.0ms preprocess, 3204.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6871.JPG: 480x640 1 person, 2186.9ms\n",
            "Speed: 4.1ms preprocess, 2186.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6895.JPG: 640x480 1 dog, 2218.1ms\n",
            "Speed: 4.0ms preprocess, 2218.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6888.JPG: 480x640 1 dog, 2236.9ms\n",
            "Speed: 4.5ms preprocess, 2236.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6875.JPG: 480x640 3 dogs, 3112.1ms\n",
            "Speed: 3.2ms preprocess, 3112.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6873.JPG: 480x640 1 dog, 1 couch, 2233.1ms\n",
            "Speed: 3.3ms preprocess, 2233.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6902.JPG: 640x480 1 person, 1 surfboard, 2248.6ms\n",
            "Speed: 4.0ms preprocess, 2248.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6893.JPG: 480x640 1 person, 2220.5ms\n",
            "Speed: 4.0ms preprocess, 2220.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6898.JPG: 640x480 1 dog, 1 bed, 3009.6ms\n",
            "Speed: 4.0ms preprocess, 3009.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6907.JPG: 480x640 1 person, 2316.9ms\n",
            "Speed: 5.8ms preprocess, 2316.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6862.JPG: 480x640 1 person, 1 dog, 1 dining table, 2199.0ms\n",
            "Speed: 3.1ms preprocess, 2199.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6877.JPG: 640x480 1 dog, 2241.8ms\n",
            "Speed: 4.5ms preprocess, 2241.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6896.JPG: 480x640 1 person, 1 dog, 2769.4ms\n",
            "Speed: 4.4ms preprocess, 2769.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6901.JPG: 640x480 1 bowl, 2696.7ms\n",
            "Speed: 5.8ms preprocess, 2696.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6911.JPG: 480x640 1 car, 1 truck, 1 dog, 2263.5ms\n",
            "Speed: 4.1ms preprocess, 2263.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6874.JPG: 480x640 3 dogs, 2288.7ms\n",
            "Speed: 4.3ms preprocess, 2288.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6880.JPG: 640x480 1 bench, 1 backpack, 3636.7ms\n",
            "Speed: 3.9ms preprocess, 3636.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6881.JPG: 640x480 1 teddy bear, 2233.3ms\n",
            "Speed: 3.8ms preprocess, 2233.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6913.JPG: 640x480 1 person, 3 bottles, 2 cups, 1 couch, 1 dining table, 2 laptops, 2275.3ms\n",
            "Speed: 4.8ms preprocess, 2275.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6892.JPG: 640x480 1 person, 1 dog, 2311.2ms\n",
            "Speed: 3.8ms preprocess, 2311.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6906.JPG: 640x480 1 cat, 1 dog, 1 book, 2655.2ms\n",
            "Speed: 4.0ms preprocess, 2655.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6885.JPG: 640x480 (no detections), 2795.6ms\n",
            "Speed: 5.7ms preprocess, 2795.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6883.JPG: 480x640 1 person, 2255.5ms\n",
            "Speed: 3.9ms preprocess, 2255.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6889.JPG: 640x480 1 car, 1 stop sign, 1 dog, 1 kite, 2285.0ms\n",
            "Speed: 4.0ms preprocess, 2285.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6865.JPG: 480x640 1 person, 2 dogs, 2239.3ms\n",
            "Speed: 3.0ms preprocess, 2239.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6887.JPG: 640x480 2 persons, 1 cat, 1 dog, 1 backpack, 2903.6ms\n",
            "Speed: 5.6ms preprocess, 2903.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6890.JPG: 640x480 1 person, 2244.7ms\n",
            "Speed: 3.9ms preprocess, 2244.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6908.JPG: 640x480 1 dog, 2246.3ms\n",
            "Speed: 3.9ms preprocess, 2246.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6866.JPG: 480x640 5 dogs, 2664.6ms\n",
            "Speed: 3.0ms preprocess, 2664.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6886.JPG: 480x640 1 person, 2 benchs, 2240.1ms\n",
            "Speed: 4.6ms preprocess, 2240.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6905.JPG: 640x480 1 person, 1 teddy bear, 2279.3ms\n",
            "Speed: 5.6ms preprocess, 2279.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6861.JPG: 384x640 4 dogs, 1 bowl, 1801.9ms\n",
            "Speed: 2.5ms preprocess, 1801.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6872.JPG: 480x640 3 dogs, 3308.0ms\n",
            "Speed: 4.1ms preprocess, 3308.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6863.JPG: 480x640 3 dogs, 2211.6ms\n",
            "Speed: 3.4ms preprocess, 2211.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6904.JPG: 640x480 1 dog, 1 couch, 1 bed, 1 book, 2240.2ms\n",
            "Speed: 4.3ms preprocess, 2240.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6894.JPG: 640x480 1 person, 1 cat, 3546.4ms\n",
            "Speed: 5.0ms preprocess, 3546.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/犬２/IMG_6900.JPG: 640x480 1 dog, 2285.2ms\n",
            "Speed: 4.0ms preprocess, 2285.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset1_data[5]))\n",
        "print(dataset1_data[5])\n",
        "print(dataset1_data[5][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxuOFZDQHxL2",
        "outputId": "d654f592-1f13-4fa6-d436-9f1ea152c619"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "[['Dogs/犬１/IMG_0606/Dog1.JPG', 'Papillon', array([          0,           0,           0, ...,     0.62408,    0.076767,           0], dtype=float32)], ['Dogs/犬１/IMG_0606/Dog2.JPG', 'Chihuahua', array([  0.0071979,           0,           0, ...,     0.21085,     0.72435,           0], dtype=float32)]]\n",
            "['Dogs/犬１/IMG_0606/Dog1.JPG', 'Papillon', array([          0,           0,           0, ...,     0.62408,    0.076767,           0], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_images(dataset_data, n_clusters):\n",
        "  features = [] # [img_path, ftrs1, ftrs2, ...]\n",
        "\n",
        "  for image_data in dataset_data:\n",
        "    for dog_data in image_data:\n",
        "      if len(dog_data) == 0:\n",
        "        continue\n",
        "      features.append(dog_data[2])\n",
        "\n",
        "  features = np.array(features)\n",
        "  pca = PCA(n_components=16)\n",
        "  pca.fit(features)\n",
        "  pca_features = pca.transform(features)\n",
        "\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "  kmeans.fit(pca_features)\n",
        "  idx = 0\n",
        "  for dogs_data in dataset_data:\n",
        "    for dog_data in dogs_data:\n",
        "      if len(dog_data) == 0:\n",
        "        continue\n",
        "      dog_data.append(kmeans.labels_[idx])\n",
        "      idx += 1\n",
        "\n",
        "  return dataset_data"
      ],
      "metadata": {
        "id": "nnPnCZNORjOz"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1_data = cluster_images(dataset1_data, 2)\n",
        "dataset2_data = cluster_images(dataset2_data, 4)"
      ],
      "metadata": {
        "id": "L8r9wjZqaAEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b4adb9-a23e-4d04-c950-eb638b39a470"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "dir_to_delete = '/content/Dog2'\n",
        "\n",
        "# Delete directory and its contents\n",
        "shutil.rmtree(dir_to_delete)"
      ],
      "metadata": {
        "id": "ctrqJ2I3OoBg"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seperate_clusters(dataset_data, dir_name, num_clusters):\n",
        "  for i in range(num_clusters):\n",
        "    dir_path = f'{dir_name}/Clusters/Cluster{i+1}'\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "  for dogs_data in dataset_data:\n",
        "    for dog_data in dogs_data:\n",
        "      if len(dog_data) == 0:\n",
        "        continue\n",
        "      img_path = dog_data[0]\n",
        "      new_path = f'{dir_name}/Clusters/Cluster{dog_data[-1]+1}/{img_path[8:15]}{img_path[17:]}'\n",
        "      shutil.copy(img_path, new_path)"
      ],
      "metadata": {
        "id": "r_klqhMSMRFB"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seperate_clusters(dataset1_data, '/content/Dog1', 2)"
      ],
      "metadata": {
        "id": "z-SBXsKkNZnV"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seperate_clusters(dataset2_data, '/content/Dog2', 4)"
      ],
      "metadata": {
        "id": "PGUv0p5JP2rN"
      },
      "execution_count": 191,
      "outputs": []
    }
  ]
}